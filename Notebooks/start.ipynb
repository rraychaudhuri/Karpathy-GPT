{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception reporting mode: Plain\n",
      "e:\\Karpathy-GPT\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# excetions show up normally\n",
    "%xmode plain\n",
    "\n",
    "# plots show up inline\n",
    "%matplotlib inline\n",
    "\n",
    "def get_device(cpu_only=True):\n",
    "    \"\"\"\n",
    "    Returns one of cuda / mps / cpu based on availablity\n",
    "    \"\"\"\n",
    "    if cpu_only is True:\n",
    "        return torch.device(\"cpu\")\n",
    "    elif torch.cuda.is_available():\n",
    "        return torch.device(\"cuda\")\n",
    "    elif torch.backends.mps.is_available():\n",
    "        return torch.device(\"mps\")\n",
    "    else:\n",
    "        return torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "# Choose the default device\n",
    "cpu_only = True\n",
    "default_device = get_device(cpu_only)\n",
    "\n",
    "\n",
    "# Needed to import modules from src\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "\n",
    "# Get Project Root (needed for reading config)\n",
    "import os\n",
    "projectRoot = os.path.dirname(os.getcwd())\n",
    "print(projectRoot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Data + Split + Create NN Input chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[58, 53, 61, 52,  6,  0, 31, 59],\n",
      "        [ 1, 51, 63,  1, 43, 39, 56, 58],\n",
      "        [51, 53, 59, 56,  0, 63, 53, 59],\n",
      "        [24, 13, 16, 37,  1, 15, 13, 28]])\n",
      "tensor([[53, 61, 52,  6,  0, 31, 59, 57],\n",
      "        [51, 63,  1, 43, 39, 56, 58, 46],\n",
      "        [53, 59, 56,  0, 63, 53, 59, 56],\n",
      "        [13, 16, 37,  1, 15, 13, 28, 33]])\n"
     ]
    }
   ],
   "source": [
    "from src.dataUtils import DataUtils\n",
    "from src.utils import get_chunk_from_data, estimateLoss\n",
    "\n",
    "\n",
    "dataUtils = DataUtils(projectRoot)\n",
    "dataUtils.initialize()\n",
    "\n",
    "train_boundary = math.floor(.8 * len(dataUtils.all_data))\n",
    "cv_boundary = math.floor(0.9 * len(dataUtils.all_data))\n",
    "\n",
    "train_data = dataUtils.all_data[:train_boundary]\n",
    "cv_data = dataUtils.all_data[train_boundary:cv_boundary]\n",
    "test_data = dataUtils.all_data[cv_boundary:]\n",
    "\n",
    "X, Y = get_chunk_from_data(train_data, batch_size=4, block_size=8, encode=dataUtils.encode)\n",
    "\n",
    "print(X)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 4.589491941928864\n",
      "--------------------------Sample From Model (Before Training) --------------------------\n",
      "mour\n",
      "youNCzVueu!jgvAo3nyLz-?Vu-PEPkPuwG:-LYga KZOnU;\n",
      "sLLZCjK-;jBSPLXZz$DL;dYnwf3YQUp'ndsUnwcvg,bwLJBBLgWazkN!duMueBgIgRtKicNOPsUK'RIir;dIUZWSZKcvDdLPDn!aOU:PIKpnoRguthpDoRtpnPi.J?gCaNiEr$BIt;kWh$UH&;VhHPsatvOEnlQKHzinirtrYKv$3q&DEu;IT KoDIgDJCG;,bYddWIwj-BUrn bWElzB aLYJSrBBUHi&hKyvSY-utrztIKBv?rR\n",
      "WiRr-w?XJbrv?CRsa;aLKUuwt&&Kb??KW-'D&O.ijuJwE3VJsEQ-q?Oi&fyrpKqeHdHihBKq?DRHHJrCc:rVEmLtWsQRtn;-BUrwwvizbaityaZzJdnnU.bfwvSHLRtLRrCt!HiihaVX'zjHkcJ-wIVtu'cnR.EME3WPWw&waKHt;yjANJhCbUaCoVStJLQdWLGyinRqPjKyOjDpR;Ddh\n",
      "ygZczILwwnwX'h-?J.LYURfe'cUn;'cN3K;DndgjQUnb&VacVEKrvj?taajKZArTZ3NJ;b&IURovqPJoYgXPD;Ln!LzdwZnQkne.KcRStXKvLRaLt$VUQa;;yLCgoIyRraYoeXXK&hAV$SDEWiI;vNju3&uStyEtuUVopWHPcrsKv?,&QKvELbuKu;qUpnr&eWA'tW;La-zHUABini&cENSbKtKyRmjfeH$Sqctu;m-KqdbaNzDab?ZgKw$zIUzIdZyuv&bYzNdJkML;KYnRKoLeLY;VHgoANljEJ&o?\n",
      "TOtgzvztLihLJd;vbeu;q$ Co-BbJ;aLBKq3P;UL-JErrLXmayzD wVmtKVZQwrKCvLJK$zgiaYvKlk.dBSZrvnkZ$Ae&uKtUQK&oStWdKwaLYdwGdw&v?HHLTi z-tbbbSALbtuwgEDgZr&igLLtNNdLXPjigKFjgJ'CwaHViowtggPZNGeBQ;LoLz:UrzI'kueNV\n"
     ]
    }
   ],
   "source": [
    "from src.gpt.baseModel import BaseModel, BaseModel_V2\n",
    "\n",
    "# Hyperparameters\n",
    "batch_size = 4\n",
    "block_size = 8\n",
    "feature_dim = 32\n",
    "learning_rate = 1e-3\n",
    "\n",
    "# Derived Params\n",
    "len_vocab = len(dataUtils.vocab)\n",
    "output_dim = len_vocab\n",
    "\n",
    "# Measurements\n",
    "training_loss = []\n",
    "cv_loss = []\n",
    "\n",
    "# model = BaseModel(vocab_length=len(dataUtils.vocab), d=default_device)\n",
    "model = BaseModel_V2(len_vocab, feature_dim, len_vocab, block_size, d=default_device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(),lr=learning_rate)\n",
    "\n",
    "# logits, loss = model(X, Y)\n",
    "print(f\"Loss: {estimateLoss(model, train_data, batch_size, block_size, dataUtils.encode, default_device)}\")\n",
    "\n",
    "print(\"--------------------------Sample From Model (Before Training) --------------------------\")\n",
    "retval = model.generate(X[2, :], max_characters=1000)\n",
    "print(dataUtils.decode(retval))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:     0\tTraining Loss: 2.48745258\tValidation Loss: 2.50367401\n",
      "Epoch:  1000\tTraining Loss: 2.49193819\tValidation Loss: 2.51191332\n",
      "Epoch:  2000\tTraining Loss: 2.50293834\tValidation Loss: 2.50685716\n",
      "Epoch:  3000\tTraining Loss: 2.48522458\tValidation Loss: 2.52123569\n",
      "Epoch:  4000\tTraining Loss: 2.46328680\tValidation Loss: 2.52008886\n",
      "Epoch:  5000\tTraining Loss: 2.50595738\tValidation Loss: 2.51240475\n",
      "Epoch:  6000\tTraining Loss: 2.49516198\tValidation Loss: 2.49979795\n",
      "Epoch:  7000\tTraining Loss: 2.50906653\tValidation Loss: 2.52594506\n",
      "Epoch:  8000\tTraining Loss: 2.49118293\tValidation Loss: 2.54958029\n",
      "Epoch:  9000\tTraining Loss: 2.48203830\tValidation Loss: 2.49192401\n"
     ]
    }
   ],
   "source": [
    "epochs = 10000\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    X, Y = get_chunk_from_data(train_data, batch_size=batch_size, block_size=block_size, encode=dataUtils.encode, d=default_device)\n",
    "    logits, loss = model(X, Y)\n",
    "\n",
    "    if epoch % 1000 == 0:\n",
    "        training_loss.append(estimateLoss(model, train_data, batch_size, block_size, dataUtils.encode, default_device))\n",
    "        cv_loss.append(estimateLoss(model, cv_data, batch_size, block_size, dataUtils.encode, default_device))\n",
    "        print(f\"Epoch:{epoch:6d}\\tTraining Loss: {training_loss[-1]:.8f}\\tValidation Loss: {cv_loss[-1]:.8f}\")\n",
    "\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sample from Model after Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------Sample From Model (After Training) --------------------------\n",
      "ed spleesourimy ay f asulod his m or thet, frdy s ge orveed thor hoomeed s'thid\n",
      "\n",
      "\n",
      "The on tooon;\n",
      "INond inourak contos!\n",
      "COMat serongfou y ag hor uryshoubenimooe w gas,\n",
      "CHithe nar frrs hes, n nstathace harou top amabid nid wus:\n",
      "Find re facinindse, hont s d plo'tortoiee w;\n",
      "Hans\n",
      "\n",
      "y; tu aceersathethelois bghecerranguroly,\n",
      "\n",
      "Theflf gweroummindith ce wisaso iemared.\n",
      "CAn ithethybeise!-\n",
      "Anes vam, d m, yon lo y.\n",
      "CPrsearowingin lld h e,\n",
      "Seroten pin the:\n",
      "Af emmfa isince atave;\n",
      "TOLO t werd o hininord wount hayozelow s\n"
     ]
    }
   ],
   "source": [
    "print(\"--------------------------Sample From Model (After Training) --------------------------\")\n",
    "retval = model.generate(X[2, :], max_characters=500)\n",
    "print(dataUtils.decode(retval))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
